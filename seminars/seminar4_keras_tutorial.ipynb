{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Keras tutorial\n",
    "\n",
    "[Keras](https://keras.io/)\n",
    "\n",
    "[Original repo](https://github.com/fchollet/keras)\n",
    "\n",
    "[Fork with MXNet support](https://github.com/dmlc/keras)\n",
    "\n",
    "[FAQ](https://keras.io/getting-started/faq/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "#### Backend\n",
    "\n",
    "- [TensorFlow installation instructions](https://www.tensorflow.org/install/)\n",
    "- Also now Keras is a part of TensorFlow as [tf.keras module](https://www.tensorflow.org/api_docs/python/tf/keras)\n",
    "- [Theano installation instructions](http://deeplearning.net/software/theano/install.html#install)\n",
    "- [CNTK installation instructions](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine)\n",
    "- [Keras with MXNet instructions](https://github.com/dmlc/keras/wiki/Installation)\n",
    "\n",
    "#### Dependencies\n",
    "\n",
    "- cuDNN (recommended if you plan on running Keras on GPU).\n",
    "- HDF5 and h5py (required if you plan on saving Keras models to disk).\n",
    "- graphviz and pydot (used by visualization utilities to plot model graphs).\n",
    "\n",
    "\n",
    "#### Install Keras from PyPI (recommended):\n",
    "\n",
    "``` bash\n",
    "pip install keras\n",
    "```\n",
    "\n",
    "#### Alternatively: install Keras from the Github source:\n",
    "\n",
    "``` bash\n",
    "git clone https://github.com/fchollet/keras.git\n",
    "cd keras\n",
    "sudo python setup.py install\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config\n",
    "\n",
    "Keras directory:\n",
    "\n",
    "```\n",
    "$HOME/.keras/                # Linux\n",
    "%USERPROFILE%/.keras/        # Windows\n",
    "$HOME/.keras/keras.json      # configuration file\n",
    "```\n",
    "\n",
    "Default configuration file:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"image_data_format\": \"channels_last\",\n",
    "    \"epsilon\": 1e-07,\n",
    "    \"floatx\": \"float32\",\n",
    "    \"backend\": \"tensorflow\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "\n",
    "1. Core layers\n",
    "    - Dense\n",
    "    - Activation|\n",
    "    - Dropout\n",
    "    - Flatten\n",
    "    - ...\n",
    "2. Convolutional layers\n",
    "    - Conv2D\n",
    "    - Upsampling2D\n",
    "    - ZeroPadding2D\n",
    "    - Cropping2D\n",
    "    - ...\n",
    "3. Pooling layers\n",
    "    - MaxPooling2D\n",
    "    - AveragePooling2D\n",
    "    - Global***\n",
    "    - ...\n",
    "4. Recurrent Layers\n",
    "    - RNN\n",
    "    - LSTM\n",
    "    - GRU\n",
    "    - ...\n",
    "5. Other\n",
    "    - Embedding layers\n",
    "    - Merge layers\n",
    "    - Advanced activations layers\n",
    "    - Normalization layers\n",
    "    - Noise layers\n",
    "6. Custom layers: https://keras.io/layers/writing-your-own-keras-layers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations\n",
    "\n",
    "1. Core\n",
    "    - softmax\n",
    "    - tanh\n",
    "    - sigmoid\n",
    "    - relu\n",
    "    - selu\n",
    "    - linear\n",
    "2. Advanced activations layers\n",
    "3. Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense\n",
    "\n",
    "# 1. Activation layer\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "# 2. Dense (or other) layer param\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "\n",
    "# 3. Backend activation\n",
    "from keras import backend as K\n",
    "\n",
    "model.add(Dense(64, activation=K.tanh))\n",
    "model.add(Activation(K.tanh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential API\n",
    "\n",
    "Easy, but Sequential model is alsways a linear stack of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(784,), activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional API\n",
    "\n",
    "- More flexible\n",
    "- Non-sequential models\n",
    "    - U-Net\n",
    "    - ResNet\n",
    "    - Multi-input and multi-output models\n",
    "    - Shared layers\n",
    "    - More examples: https://keras.io/getting-started/functional-api-guide/\n",
    "\n",
    "\n",
    "- A layer instance is callable (on a tensor), and it returns a tensor\n",
    "- All models are callable, just like layers\n",
    "- Input tensor(s) and output tensor(s) can then be used to define a Model\n",
    "- Such a model can be trained just like Keras Sequential models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "\n",
    "# Input tensor for sequences of 20 timesteps,\n",
    "# each containing a 784-dimensional vector\n",
    "input_sequences = Input(shape=(20, 784))\n",
    "\n",
    "# This applies our previous model to every timestep in the input sequences.\n",
    "# the output of the previous model was a 10-way softmax,\n",
    "# so the output of the layer below will be a sequence of 20 vectors of size 10.\n",
    "processed_sequences = TimeDistributed(model)(input_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn API\n",
    "\n",
    "**Not recommended**\n",
    "\n",
    "There are two wrappers available:\n",
    "\n",
    "- keras.wrappers.scikit_learn.KerasClassifier(build_fn=None, **sk_params)\n",
    "- keras.wrappers.scikit_learn.KerasRegressor(build_fn=None, **sk_params)\n",
    "\n",
    "\n",
    "Arguments\n",
    "\n",
    "- build_fn: callable function or class instance\n",
    "- sk_params: model parameters & fitting parameters\n",
    "\n",
    "More info: https://keras.io/scikit-learn-api/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training a model, we need to configure the learning process, which is done via the *compile()* method.\n",
    "\n",
    "#### compile() arguments:\n",
    "\n",
    "- optimizer\n",
    "    - the string identifier of an existing optimizer (such as rmsprop or adagrad)\n",
    "    - or an instance of the  Optimizer class\n",
    "- loss\n",
    "    - This is the objective that the model will try to minimize\n",
    "    - the string identifier of an existing loss function (such as categorical_crossentropy or mse)\n",
    "    - or it can be an objective function\n",
    "- metrics \n",
    "    - List of metrics\n",
    "    - Each metric is:\n",
    "        - the string identifier of an existing metric\n",
    "        - or a custom metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a multi-class classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# For a binary classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# For a mean squared error regression problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Custom metric and loss\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + (1 - dice_loss(y_true, y_pred))\n",
    "\n",
    "model.compile(optimizer=Adam(1e-3), loss=bce_dice_loss, metrics=[dice_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Model class has 3 versions of fit (and evaluate/predict) methods:\n",
    "\n",
    "- **fit** - trains the model for a fixed number of epochs (iterations on a dataset)\n",
    "- **fit_generator** - fits the model on data yielded batch-by-batch by a Python generator\n",
    "    - The generator is run in parallel to the model, for efficiency. For instance, this allows you to do real-time data augmentation on images on CPU in parallel to training your model on GPU.\n",
    "    - The use of keras.utils.Sequence guarantees the ordering and guarantees the single use of every input per epoch when using use_multiprocessing=True.\n",
    "- **train_on_batch** - runs a single gradient update on a single batch of data.\n",
    "\n",
    "More info: https://keras.io/models/model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit() examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a single-input model with 2 classes (binary classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a single-input model with 10 classes (categorical classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit_generator() example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(ids_train_split, batch_size):\n",
    "    while True:\n",
    "        for start in range(0, len(ids_train_split), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + batch_size, len(ids_train_split))\n",
    "            ids_train_batch = ids_train_split[start:end]\n",
    "            for id in ids_train_batch.values:\n",
    "                img = cv2.imread(os.path.join(TRAIN_DIR, '{}.jpg'.format(id)))\n",
    "                mask = scm.imread(os.path.join(MASK_DIR, '{}_mask.gif'.format(id)), mode='L')\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "            x_batch = np.array(x_batch, np.float32) / 255\n",
    "            y_batch = np.array(y_batch, np.float32) / 255\n",
    "            yield x_batch, y_batch\n",
    "\n",
    "def val_generator(ids_val_split, batch_size):\n",
    "    while True:\n",
    "        for start in range(0, len(ids_val_split), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + batch_size, len(ids_val_split))\n",
    "            ids_valid_batch = ids_val_split[start:end]\n",
    "            for id in ids_valid_batch.values:\n",
    "                img = cv2.imread(os.path.join(TRAIN_DIR, '{}.jpg'.format(id)))\n",
    "                mask = scm.imread(os.path.join(MASK_DIR, '{}_mask.gif'.format(id)), mode='L')\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "            x_batch = np.array(x_batch, np.float32) / 255\n",
    "            y_batch = np.array(y_batch, np.float32) / 255\n",
    "            yield x_batch, y_batch\n",
    "\n",
    "model.fit_generator(generator=train_generator(ids_train_split, batch_size),\n",
    "        steps_per_epoch=np.ceil(float(len(ids_train_split)) / float(batch_size)),\n",
    "        validation_data=val_generator(ids_val_split, batch_size),\n",
    "        validation_steps=np.ceil(float(len(ids_val_split)) / float(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images\n",
    "\n",
    "https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-6,\n",
    "    rotation_range=0.,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    shear_range=0.,\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=K.image_data_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[imgaug](https://github.com/aleju/imgaug) - cool image augmentation library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text\n",
    "\n",
    "https://keras.io/preprocessing/text/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.preprocessing.text.text_to_word_sequence(text,\n",
    "                                               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                               lower=True,\n",
    "                                               split=\" \")\n",
    "\n",
    "keras.preprocessing.text.one_hot(text,\n",
    "                                 n,\n",
    "                                 filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                 lower=True,\n",
    "                                 split=\" \")\n",
    "\n",
    "keras.preprocessing.text.hashing_trick(text, \n",
    "                                       n,\n",
    "                                       hash_function=None,\n",
    "                                       filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                       lower=True,\n",
    "                                       split=' ')\n",
    "\n",
    "keras.preprocessing.text.Tokenizer(num_words=None,\n",
    "                                   filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                   lower=True,\n",
    "                                   split=\" \",\n",
    "                                   char_level=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequences\n",
    "\n",
    "https://keras.io/preprocessing/sequence/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype='int32',\n",
    "    padding='pre', truncating='pre', value=0.)\n",
    "    \n",
    "keras.preprocessing.sequence.skipgrams(sequence, vocabulary_size,\n",
    "    window_size=4, negative_samples=1., shuffle=True,\n",
    "    categorical=False, sampling_table=None)\n",
    "    \n",
    "keras.preprocessing.sequence.make_sampling_table(size, sampling_factor=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load models\n",
    "\n",
    "#### Saving/loading whole models (architecture + weights + optimizer state)\n",
    "\n",
    "pickle or cPickle is not recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# HDF5 file contains:\n",
    "#     - the architecture of the model, allowing to re-create the model\n",
    "#     - the weights of the model\n",
    "#     - the training configuration (loss, optimizer)\n",
    "#     - the state of the optimizer, allowing to resume training exactly where you left off.\n",
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "# returns a compiled model identical to the previous one\n",
    "# load_model will also take care of compiling the model using the saved training configuration\n",
    "# (unless the model was never compiled in the first place)\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving/loading only a model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save as JSON\n",
    "json_string = model.to_json()\n",
    "\n",
    "# save as YAML\n",
    "yaml_string = model.to_yaml()\n",
    "\n",
    "# The generated JSON / YAML files are human-readable and can be manually edited if needed.\n",
    "\n",
    "\n",
    "# model reconstruction from JSON:\n",
    "from keras.models import model_from_json\n",
    "model = model_from_json(json_string)\n",
    "\n",
    "# model reconstruction from YAML\n",
    "from keras.models import model_from_yaml\n",
    "model = model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving/loading only a model's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights.h5')\n",
    "\n",
    "# Assuming you have code for instantiating your model,\n",
    "# you can then load the weights you saved into a model with the same architecture:\n",
    "model.load_weights('my_model_weights.h5')\n",
    "\n",
    "# If you need to load weights into a different architecture (with some layers in common),\n",
    "# for instance for fine-tuning or transfer-learning, you can load weights by layer name:\n",
    "# # #\n",
    "# Assuming the original model looks like this:\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(2, input_dim=3, name='dense_1'))\n",
    "#     model.add(Dense(3, name='dense_2'))\n",
    "#     ...\n",
    "#     model.save_weights(fname)\n",
    "# # #\n",
    "\n",
    "# new model\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=3, name='dense_1'))  # will be loaded\n",
    "model.add(Dense(10, name='new_dense'))  # will not be loaded\n",
    "\n",
    "# load weights from first model; will only affect the first layer, dense_1.\n",
    "model.load_weights(fname, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling custom layers (or other custom objects) in saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# Assuming your model includes instance of an \"AttentionLayer\" class\n",
    "model = load_model('my_model.h5', custom_objects={'AttentionLayer': AttentionLayer, 'dice_loss': dice_loss})\n",
    "\n",
    "# Alternatively, you can use a custom object scope:\n",
    "from keras.utils import CustomObjectScope\n",
    "\n",
    "with CustomObjectScope({'AttentionLayer': AttentionLayer}):\n",
    "    model = load_model('my_model.h5')\n",
    "\n",
    "# Custom objects handling works the same way for load_model, model_from_json, model_from_yaml:\n",
    "from keras.models import model_from_json\n",
    "model = model_from_json(json_string, custom_objects={'AttentionLayer': AttentionLayer})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=784, kernel_initializer='uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "'''\n",
    "saves the model weights after each epoch if the validation loss decreased\n",
    "'''\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss',\n",
    "                        patience=5,\n",
    "                        verbose=1,\n",
    "                        min_delta=1e-6,\n",
    "                        mode='max'),\n",
    "    ReduceLROnPlateau(monitor='val_loss',\n",
    "                        factor=0.2,\n",
    "                        patience=5,\n",
    "                        min_lr=0.001),\n",
    "    ModelCheckpoint(filepath='/tmp/weights.hdf5',\n",
    "                        verbose=1,\n",
    "                        save_best_only=True,\n",
    "                        save_only_weights=True),\n",
    "    TensorBoard(log_dir='/tmp/')\n",
    "]\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=0,\n",
    "          validation_data=(X_test, Y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Model ZOO](https://keras.io/applications/)\n",
    "\n",
    "- Xception (only TF)\n",
    "- VGG16\n",
    "- VGG19\n",
    "- ResNet50\n",
    "- InceptionV3\n",
    "- InceptionResNetV2\n",
    "- MobileNet (only TF)\n",
    "\n",
    "More models: just google \"[framework name] [model name]\" e.g. \"keras densenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "\n",
    "#### Freeze layers\n",
    "\n",
    "To \"freeze\" a layer = to exclude it from training = its weights will never be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. pass a trainable argument (boolean) to a layer constructor:\n",
    "\n",
    "frozen_layer = Dense(32, trainable=False)\n",
    "\n",
    "# 2. set the trainable property of a layer after instantiation\n",
    "# need to call compile() after modifying the trainable property\n",
    "\n",
    "x = Input(shape=(32,))\n",
    "layer = Dense(32)\n",
    "layer.trainable = False\n",
    "y = layer(x)\n",
    "\n",
    "frozen_model = Model(x, y)\n",
    "# in the model below, the weights of `layer` will not be updated during training\n",
    "frozen_model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "layer.trainable = True\n",
    "trainable_model = Model(x, y)\n",
    "# with this model the weights of the layer will be updated during training\n",
    "# (which will also affect the above model since it uses the same layer instance)\n",
    "trainable_model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "frozen_model.fit(data, labels)  # this does NOT update the weights of `layer`\n",
    "trainable_model.fit(data, labels)  # this updates the weights of `layer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tune InceptionV3 on a new set of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(...)\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit_generator(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
