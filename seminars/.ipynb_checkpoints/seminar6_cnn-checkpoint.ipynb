{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torchvision\n",
    "\n",
    "[torchvision](https://github.com/pytorch/vision) - библиотека, содержащая популярные CV датасеты, утилиты для препроцессинга и, самое важное, pre-trained модели для классификации, обученные на [ImageNet](http://image-net.org/).\n",
    "\n",
    "Большая часть потребностей покрывается имеющимися моделями, но если нужна какая-то другая архитектура или нужно решать задачу, отличную от классификации, то хорошую реализацию и веса, скорее всего, получится нагуглить или найти на github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models as M\n",
    "\n",
    "model = M.resnet50(pretrained=True)\n",
    "model.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как достать признаки?\n",
    "\n",
    "- переопределить последний слой так, чтобы он ничего не делал (неплохой вариант, но что, если нужны признаки из внутрненнего слоя?)\n",
    "- написать хук, который будет возвращать признаки (хороший вариант)\n",
    "- покромсать сетку и делать forward pass только для тех слоев, которые нужны (плохой вариант)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 1. Переопределить последний слой\n",
    "\n",
    "***ВНИМАНИЕ 1:*** Серьезная проблема `torchvision` - отсутствие единого интерфейса у моделей. В каждой реализации слои имеют разные имена и при единовременной работе с разными моделями приходится писать обвязку из условий. Если использовать реализации других архитектур, то ситуация только ухудшается\n",
    "\n",
    "***ВНИМАНИЕ 2:*** В отличие от **Keras**, в **PyTorch** не принято делать последним слоем активацию. Нужная функция применяется при написании train / inference кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from copy import deepcopy\n",
    "\n",
    "model = M.resnet50(pretrained=True)\n",
    "features_model = deepcopy(model)\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "        \n",
    "features_model.fc = Identity()\n",
    "\n",
    "dummy_x = Variable(torch.randn(1, 3, 224, 224))\n",
    "features = features_model(dummy_x)\n",
    "features_shape = features.data.numpy().shape\n",
    "assert features_shape == (1, 2048), 'expected (1, 2048), but real is {}'.format(features_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 2. Forward hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "avgpool_features = None\n",
    "\n",
    "def get_features(module, inputs, output):\n",
    "    global avgpool_features   \n",
    "    avgpool_features = np.squeeze(output.data.cpu().numpy(), axis=(2, 3))\n",
    "\n",
    "model = M.resnet50(pretrained=True)\n",
    "model.avgpool.register_forward_hook(get_features)\n",
    "\n",
    "dummy_x = Variable(torch.randn(1, 3, 224, 224))\n",
    "model(dummy_x)\n",
    "\n",
    "assert avgpool_features.shape == (1, 2048), 'expected (1, 2048), but real is {}'.format(avgpool_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение на признаках\n",
    "\n",
    "Обучим обычный sklearn-классификатор, которому на вход подадим признаки из нейросети\n",
    "\n",
    "В качестве датасета будем использовать данные конкурса https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "\n",
    "Датасет содержит 25000 изображений кошек и собак, по 12500 каждого класса. Задача: определить, к какому классу относится конкретное изображение\n",
    "\n",
    "Для определения качества моделей будем использовать метрику ROC-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем и подготовим данные. Выделим 30% на валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cat_fnames = glob.glob('./train/cat.*.jpg')\n",
    "dog_fnames = glob.glob('./train/dog.*.jpg')\n",
    "all_names = cat_fnames + dog_fnames\n",
    "labels = np.array([0] * len(cat_fnames) + [1] * len(dog_fnames))\n",
    "\n",
    "train_fnames, val_fnames, y_train, y_val = train_test_split(all_names, labels, test_size=0.3,\n",
    "                                                            random_state=42, shuffle=True, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В **PyTorch** можно удобно работать с данными с помощью классов `Dataset` и `DataLoader`\n",
    "\n",
    "Напишем свой датасет для расчет признаков изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from scipy.misc import imread, imresize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "\n",
    "class FeaturesDataset(Dataset):\n",
    "    def __init__(self, fnames, shape):\n",
    "        self._fnames = fnames\n",
    "        self._shape = shape\n",
    "        self._transform = Compose([\n",
    "            ToTensor(),\n",
    "            Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fname = self._fnames[index]\n",
    "        img = cv2.imread(fname)\n",
    "        img = cv2.resize(img, self._shape)\n",
    "        img = self._transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно как-то рассчитать признаки.\n",
    "\n",
    "Воспользуемся способом с хуком, но чтобы обойтись без глобальной переменной реализуем класс `FeatureExtractor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, model, device='cuda'):\n",
    "        self._model = model\n",
    "        self._avgpool_features = None\n",
    "        self._device = device\n",
    "        self._model.avgpool.register_forward_hook(self._get_features)\n",
    "\n",
    "    def get_dataset_features(self, loader):\n",
    "        self._model.eval().to(self._device)\n",
    "        features = []\n",
    "        for sample in tqdm(loader):\n",
    "            _ = self._model(sample.to(self._device))\n",
    "            features.append(self._avgpool_features)\n",
    "        return np.concatenate(features)\n",
    "\n",
    "    def _get_features(self, module, inputs, output):\n",
    "        self._avgpool_features = np.squeeze(output.data.cpu().numpy(), axis=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2188/2188 [03:59<00:00,  9.14it/s]\n",
      "100%|████████████████████████████████████████| 938/938 [01:44<00:00,  8.98it/s]\n"
     ]
    }
   ],
   "source": [
    "model = M.resnet50(pretrained=True)\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 0\n",
    "shape = (224, 224)\n",
    "\n",
    "train_dataset = FeaturesDataset(train_fnames, shape)\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=False, num_workers=num_workers)\n",
    "val_dataset = FeaturesDataset(val_fnames, shape)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "extractor = FeatureExtractor(model, device='cuda')\n",
    "\n",
    "train_features = extractor.get_dataset_features(train_loader)\n",
    "val_features = extractor.get_dataset_features(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно взять любой из известных классификаторов и подать найденные признаки на вход\n",
    "\n",
    "Должен получитсься очень хороший ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAX\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_roc_auc(y_val, y_pred, model_name):\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    plt.plot(*roc_curve(y_val, y_pred)[:2], label='{} AUC={:.4f}'.format(model_name, auc))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], '--', color='black')\n",
    "    plt.legend(fontsize='large')\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(val_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_auc(y_val, y_pred, model_name='RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем добиться лучшего качества модели путем ее дообучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import models as M\n",
    "\n",
    "\n",
    "class ResnetFinetune(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResnetFinetune, self).__init__()\n",
    "        self.net = M.resnet50(pretrained=True)\n",
    "        self.net.fc = nn.Sequential(\n",
    "            nn.Linear(self.net.fc.in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def fresh_parameters(self):\n",
    "        return self.net.fc.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from scipy.misc import imread, imresize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "\n",
    "class CatsDogsDataset(Dataset):\n",
    "    def __init__(self, fnames, labels, shape):\n",
    "        self._fnames = fnames\n",
    "        self._labels = labels\n",
    "        self._shape = shape\n",
    "        self._transform = Compose([\n",
    "            ToTensor(),\n",
    "            Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fname = self._fnames[index]\n",
    "        img = cv2.imread(fname)\n",
    "        img = cv2.resize(img, self._shape)\n",
    "        img = self._transform(img)\n",
    "        return img, self._labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correct(y_true, y_pred):\n",
    "    correct = (y_true == y_pred).squeeze()\n",
    "    return correct.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Trainer:    \n",
    "    def __init__(self, model, criterion, config, device='cuda'):\n",
    "        self._model = model\n",
    "        self._device = device\n",
    "        self._criterion = criterion\n",
    "        self._epochs = config['epochs']\n",
    "\n",
    "        if config['only_top']:\n",
    "            self._optimizer = Adam(self._model.fresh_parameters(), lr=config['lr'])\n",
    "        else:\n",
    "            self._optimizer = Adam(self._model.parameters(), lr=config['lr'])        \n",
    "\n",
    "        self._model.to(self._device)\n",
    "\n",
    "    def fit(self, train_loader, val_loader):\n",
    "        for epoch in range(self._epochs):\n",
    "            self._model.train()\n",
    "            train_loss, train_accuracy = self._run_epoch(epoch, train_loader, is_training=True)\n",
    "            print('Train. loss: {}, accuracy: {}'.format(train_loss, train_accuracy))\n",
    "            \n",
    "            self._model.eval()\n",
    "            val_loss, val_accuracy = self._run_epoch(epoch, val_loader, is_training=False)\n",
    "            print('Validation. loss: {}, accuracy: {}'.format(val_loss, val_accuracy))\n",
    "\n",
    "    def _run_epoch(self, epoch, loader, is_training):\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        if is_training:\n",
    "            pbar = tqdm(enumerate(loader), total=len(loader), desc='Epoch {}'.format(epoch), ncols=0)\n",
    "        else:\n",
    "            pbar = tqdm(enumerate(loader), total=len(loader), desc='Val', ncols=0)\n",
    "        \n",
    "        for i, data in pbar:\n",
    "            batch_loss, batch_correct = self._step(data, is_training)\n",
    "            loss += batch_loss\n",
    "            correct += batch_correct\n",
    "                    \n",
    "        loss /= len(loader)\n",
    "        accuracy = correct / len(loader.dataset)\n",
    "        return loss, accuracy\n",
    "    \n",
    "    def _step(self, data, is_training=True):\n",
    "        images = data[0].to(self._device)\n",
    "        y_true = data[1].to(self._device)\n",
    "\n",
    "        if is_training:\n",
    "            self._optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(is_training):\n",
    "            y_pred = self._model(images)\n",
    "            y_pred = y_pred.squeeze()\n",
    "            loss = self._criterion(y_pred, y_true.float())\n",
    "\n",
    "            if is_training:\n",
    "                loss.backward()\n",
    "                self._optimizer.step()\n",
    "            \n",
    "        probas = torch.sigmoid(y_pred)\n",
    "        labels = (probas > 0.5).int()\n",
    "        correct = calculate_correct(y_true=y_true, y_pred=labels)\n",
    "        return loss.item(), correct.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала будем учить только добавленные нами слои"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetFinetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_workers = 0\n",
    "shape = (224, 224)\n",
    "\n",
    "train_dataset = CatsDogsDataset(train_fnames, y_train, shape)\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "val_dataset = CatsDogsDataset(val_fnames, y_val, shape)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100% 2188/2188 [06:32<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.20357629037779285, accuracy: 0.9174857142857142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:06<00:00, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.0708706068262996, accuracy: 0.9746666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100% 2188/2188 [06:25<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.15919941237307103, accuracy: 0.9354285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:05<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.06214890348706901, accuracy: 0.9808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100% 2188/2188 [06:24<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.1522085330894328, accuracy: 0.9385714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:05<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.06123416478880175, accuracy: 0.9802666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100% 2188/2188 [06:20<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.1426537160184792, accuracy: 0.9428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:04<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.0619306501515339, accuracy: 0.9762666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100% 2188/2188 [06:18<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.13953472722331964, accuracy: 0.9446857142857142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:06<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.0663592719952103, accuracy: 0.9764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100% 2188/2188 [06:18<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.141493179957707, accuracy: 0.9446285714285715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:04<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.05414866605471484, accuracy: 0.9805333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100% 2188/2188 [06:18<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.13268893576146243, accuracy: 0.9461142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:04<00:00, 15.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.05404190184409928, accuracy: 0.9808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100% 2188/2188 [06:20<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.13072011231860742, accuracy: 0.9488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:04<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.07809888640762484, accuracy: 0.9670666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100% 2188/2188 [06:18<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.11842062692345211, accuracy: 0.9532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:05<00:00, 15.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.045221996445895876, accuracy: 0.9821333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100% 2188/2188 [06:19<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.11777840266427993, accuracy: 0.9517714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:05<00:00, 15.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.04322098357876008, accuracy: 0.9814666666666667\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "config = {\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 10,\n",
    "    'only_top': True\n",
    "}\n",
    "\n",
    "trainer = Trainer(model, BCEWithLogitsLoss(), config, device='cuda')\n",
    "trainer.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Evaluator:    \n",
    "    def __init__(self, model, device='cuda'):\n",
    "        self._model = model\n",
    "        self._device = device\n",
    "\n",
    "    def predict(self, loader):\n",
    "        y_pred = []\n",
    "        self._model.eval().to(self._device)\n",
    "        \n",
    "        for i, data in tqdm(enumerate(loader), total=len(loader)):\n",
    "            batch_pred = self._step(data)\n",
    "            y_pred.append(batch_pred)\n",
    "        \n",
    "        return np.concatenate(y_pred)\n",
    "    \n",
    "    def _step(self, data, is_training=True):\n",
    "        images = data[0].to(self._device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred = self._model(images)\n",
    "        \n",
    "        y_pred = y_pred.squeeze()\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        return y_pred.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 938/938 [01:04<00:00, 16.01it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(model, device='cuda')\n",
    "y_pred = evaluator.predict(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_auc(y_val, y_pred, model_name='Resnet finetuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разморозим все веса и обучим несколько эпох с низким *learning rate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100% 2188/2188 [08:03<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.12114655467431099, accuracy: 0.9549142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:06<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.06073368054351632, accuracy: 0.9757333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100% 2188/2188 [08:31<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.06696203611710842, accuracy: 0.9769142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:09<00:00, 15.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.0728148212397997, accuracy: 0.9717333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100% 2188/2188 [08:17<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.05439092697022357, accuracy: 0.9811428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:06<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.05090371531722859, accuracy: 0.9792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100% 2188/2188 [08:26<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.047493006413392644, accuracy: 0.9831428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:08<00:00, 15.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.0758628718194775, accuracy: 0.9668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100% 2188/2188 [08:17<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.036709289235131, accuracy: 0.9853714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:06<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.15548500221863884, accuracy: 0.9337333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100% 2188/2188 [08:57<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.03432262711153319, accuracy: 0.9881714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:15<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.15912538152665634, accuracy: 0.9510666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100% 2188/2188 [08:13<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.03408647150430046, accuracy: 0.9881142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:06<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.05869730076193915, accuracy: 0.9784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100% 2188/2188 [08:10<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.02596861609509063, accuracy: 0.9907428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:04<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.07158381473956447, accuracy: 0.9770666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100% 2188/2188 [08:05<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.02249882251962645, accuracy: 0.9926857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:05<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.07577532035220629, accuracy: 0.9729333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100% 2188/2188 [08:07<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.023084395240552506, accuracy: 0.9915428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100% 938/938 [01:10<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.07508436467607098, accuracy: 0.9756\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "config = {\n",
    "    'lr': 1e-4,\n",
    "    'epochs': 10,\n",
    "    'only_top': False\n",
    "}\n",
    "\n",
    "trainer = Trainer(model, BCEWithLogitsLoss(), config, device='cuda')\n",
    "trainer.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 938/938 [01:06<00:00, 15.84it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(model, device='cuda')\n",
    "y_pred = evaluator.predict(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_auc(y_val, y_pred, model_name='Resnet finetuned no freeze')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пишем свою CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Типичные ошибки\n",
    "\n",
    "Рассмотрим несколько примеров архитектур в связке с функциями потерь и попробуем найти какие-то проблемы\n",
    "\n",
    "Для простоты будем использовать `nn.Sequential`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.modules.loss import MSELoss, BCELoss, BCEWithLogitsLoss\n",
    "\n",
    "\n",
    "# [batch, channel, w, h] -> [batch, units]\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 1\n",
    "\n",
    "Предсказать стоимость автомобиля, на вход 100 признаков, описывающих автомобиль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.BatchNorm2d(num_features=100),\n",
    "    nn.Linear(in_features=3, out_features=256),\n",
    "    nn.Linear(in_features=256, out_features=256),\n",
    "    nn.Linear(in_features=256, out_features=1)\n",
    ")\n",
    "\n",
    "loss = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.BatchNorm2d(num_features=100),\n",
    "    # не ошибка, но обычно лучше нормализовать входы\n",
    "    # однако в pytorch довольно медленная реализация Normalize\n",
    "\n",
    "    nn.Linear(in_features=3, out_features=256),\n",
    "    # неправильное число входов\n",
    "    nn.Linear(in_features=256, out_features=256),\n",
    "    # полносвязные слои без нелинейностей (нейросеть не лучше линейной регрессии)\n",
    "    \n",
    "    nn.Linear(in_features=256, out_features=1)\n",
    "    # а здесь нет ошибки, нелинейность не нужна, т.к. решаем задачу регрессии\n",
    ")\n",
    "\n",
    "loss = MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 2\n",
    "\n",
    "MNIST: Распознать рукописную цифру (0-9), на вход ч/б картинка 28x28 пикселей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=512, kernel_size=(3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d((2, 2)),\n",
    "    nn.Conv2d(in_channels=512, out_channels=256, kernel_size=(3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    nn.Linear(in_features=256, out_features=100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    \n",
    "    nn.Linear(in_features=100, out_features=10),\n",
    "    nn.Softmax(),\n",
    "    nn.Dropout(0.1)\n",
    ")\n",
    "\n",
    "loss = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=512, kernel_size=(3, 3)),\n",
    "    # 1. у нас ч/б картинки, значит 1 входной канал, а не 3\n",
    "    # 2. многовато фильтров, вряд ли найдётся 512 значимо разных 3x3 карты\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d((2, 2)),\n",
    "    # не ошибка, но relu и max pool можно переставить местами\n",
    "    \n",
    "    nn.Conv2d(in_channels=512, out_channels=256, kernel_size=(3, 3)),\n",
    "    # обычно в каждом следующем слое требуется больше фильтров\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    nn.Linear(in_features=256, out_features=100),\n",
    "    # 1. неправильное значение in_features, должно быть 5*5*256\n",
    "    # 2. возможно, слишком резкий переход от 5*5*256 к 100\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    # не ошибка, хороший dropout\n",
    "    \n",
    "    nn.Linear(in_features=100, out_features=10),\n",
    "    nn.Sigmoid(),\n",
    "    # 1. многоклассовая классификация, поэтому нужен softmax\n",
    "    # 2. в pytorch принято, чтобы последним слоем был линейный, а softmax применялся в train / inference коде\n",
    "    \n",
    "    nn.Dropout(0.25)\n",
    "    # не стоит делать dropout на выходе, есть риск получить бесконечный лосс (сумма вероятностей не равна 1)\n",
    ")\n",
    "\n",
    "loss = MSELoss()\n",
    "# не стоит учить классификацию с MSE лоссом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 3\n",
    "\n",
    "Бинарная классификация изображений, на вход картинка RGB 100x100 пикселей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(10, 10)),\n",
    "    nn.Softmax(),\n",
    "    nn.MaxPool2d((6, 6)),\n",
    "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(10, 10)),\n",
    "    nn.Softmax(),\n",
    "    nn.MaxPool2d((6, 6)),\n",
    "    nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(10, 10)),\n",
    "    nn.Softmax(),\n",
    "    nn.MaxPool2d((6, 6)),\n",
    "    \n",
    "    Flatten(),\n",
    "    nn.Linear(in_features=128, out_features=256),\n",
    "    nn.Softmax(),\n",
    "    nn.Dropout(0.8),\n",
    "    nn.Linear(in_features=256, out_features=1)\n",
    ")\n",
    "\n",
    "loss = BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(10, 10)),\n",
    "    # слишком большой размер ядра 10x10\n",
    "    \n",
    "    nn.Softmax(),\n",
    "    # softmax - плохой вариант для промежуточных активаций (почти все нейроны будут близки к 0)\n",
    "    \n",
    "    nn.MaxPool2d((6, 6)),\n",
    "    # очень редко нужен пулинг с таким большим ядром\n",
    "    \n",
    "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(10, 10)),\n",
    "    nn.Softmax(),\n",
    "    nn.MaxPool2d((6, 6)),\n",
    "    nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(10, 10)),\n",
    "    # изображение в этотм момент будет 1х1, а размер ядра 10x10\n",
    "    # Вывод: нужно следить за размерностями внутри сети\n",
    "    nn.Softmax(),\n",
    "    nn.MaxPool2d((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    nn.Linear(in_features=128, out_features=256),\n",
    "    # неправильное число in_features, нужно считать в зависмости от размеров ядер сверток и пулингов\n",
    "    nn.Softmax(),\n",
    "    nn.Dropout(0.8),\n",
    "    nn.Linear(in_features=256, out_features=1)\n",
    "    # в зависимости от использумой далее функции количество нейронов может быть равным 1 или 2\n",
    "    # sigmoid - 1, softmax - 2\n",
    ")\n",
    "\n",
    "loss = BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST\n",
    "\n",
    "Напишем свою сетку для решения задачи распознавания рукописных чисел\n",
    "\n",
    "Датасет содержит ч/б изображения размером 28x28 пикселей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем `early_stopping` и попробуем `lr_scheduler.ReduceLROnPlateau`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAX\\Anaconda3\\lib\\site-packages\\tqdm\\autonotebook\\__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.autonotebook import tqdm\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MNISTTrainer:    \n",
    "    def __init__(self, model, criterion, config, device='cuda'):\n",
    "        self._model = model\n",
    "        self._device = device\n",
    "        self._criterion = criterion\n",
    "        \n",
    "        self._model.to(self._device)\n",
    "        \n",
    "        self._epochs = config['epochs']\n",
    "        self._early_stopping = config['early_stopping']\n",
    "              \n",
    "        self._optimizer = Adam(self._model.parameters(), lr=config['lr'])\n",
    "        self._scheduler = ReduceLROnPlateau(self._optimizer,\n",
    "                                            'min',\n",
    "                                            factor=config['lr_reduce_rate'],\n",
    "                                            patience=config['patience'],\n",
    "                                            verbose=True)\n",
    "        \n",
    "        self._best_loss = float('inf')\n",
    "        self._best_epoch = -1\n",
    "\n",
    "    def fit(self, train_loader, val_loader):\n",
    "        for epoch in range(self._epochs):\n",
    "            self._model.train()\n",
    "            train_loss, train_accuracy = self._run_epoch(epoch, train_loader, is_training=True)\n",
    "            print('Train. loss: {}, accuracy: {}'.format(train_loss, train_accuracy))\n",
    "            \n",
    "            self._model.eval()\n",
    "            val_loss, val_accuracy = self._run_epoch(epoch, val_loader, is_training=False)\n",
    "            print('Validation. loss: {}, accuracy: {}'.format(val_loss, val_accuracy))\n",
    "\n",
    "            self._scheduler.step(val_loss)\n",
    "           \n",
    "            if self._best_loss > val_loss:\n",
    "                self._best_loss = val_loss\n",
    "                self._best_epoch = epoch\n",
    "\n",
    "            if abs(self._best_epoch - epoch) > self._early_stopping:\n",
    "                print('Early stopping. Epoch {}. Best epoch: {}, best {}: {}'.format(epoch, self._best_epoch))\n",
    "                break\n",
    "    \n",
    "    def _run_epoch(self, epoch, loader, is_training):\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        if is_training:\n",
    "            pbar = tqdm(enumerate(loader), total=len(loader), desc='Epoch {}'.format(epoch))\n",
    "        else:\n",
    "            pbar = enumerate(loader)\n",
    "        \n",
    "        for i, data in pbar:\n",
    "            batch_loss, batch_correct = self._step(data, is_training)\n",
    "            loss += batch_loss\n",
    "            correct += batch_correct\n",
    "\n",
    "        loss /= len(loader)\n",
    "        accuracy = correct / len(loader.dataset)\n",
    "        return loss, accuracy\n",
    "    \n",
    "    def _step(self, data, is_training=True):\n",
    "        metrics_values = {}\n",
    "        images = data[0].to(self._device)\n",
    "        y_true = data[1].to(self._device)\n",
    "\n",
    "        if is_training:\n",
    "            self._optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(is_training):\n",
    "            y_pred = self._model(images)\n",
    "            y_pred = y_pred.squeeze()\n",
    "            loss = self._criterion(y_pred, y_true)\n",
    "\n",
    "            if is_training:\n",
    "                loss.backward()\n",
    "                self._optimizer.step()\n",
    "            \n",
    "        probas = torch.softmax(y_pred, dim=0)\n",
    "        labels = probas.max(1)[1]\n",
    "        correct = calculate_correct(y_true=y_true, y_pred=labels)\n",
    "        return loss.item(), correct.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "\n",
    "class MNISTModel(Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d((2, 2))\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3))\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3))\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3))\n",
    "        self.drop = nn.Dropout2d(p=0.5)\n",
    "\n",
    "        self.classifier = nn.Linear(in_features=128, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.drop(x)\n",
    "    \n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor, RandomRotation\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 0\n",
    "\n",
    "\n",
    "train_transform = Compose([\n",
    "    RandomRotation(degrees=(-10, 10)),\n",
    "    ToTensor(),\n",
    "    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "train_dataset = MNIST(root='mnist', train=True, download=True, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "val_transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "val_dataset = MNIST(root='mnist', train=False, transform=val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b59402cb9a94083b40c461352fe4481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train. loss: 0.4698141474745421, accuracy: 0.7310166666666666\n",
      "Validation. loss: 0.08518739551258316, accuracy: 0.9453\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621f5fcad4644d1a9b64b7258f5e1823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train. loss: 0.1538636911449942, accuracy: 0.8352166666666667\n",
      "Validation. loss: 0.044814677256497605, accuracy: 0.965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a632d611f664c6ca6b28ff996df9228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train. loss: 0.11120733504157776, accuracy: 0.86045\n",
      "Validation. loss: 0.03931238737170863, accuracy: 0.9694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11fb4e923fd4968a1120f063a6140c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train. loss: 0.08966628759344822, accuracy: 0.874\n",
      "Validation. loss: 0.0326353631866206, accuracy: 0.9717\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e923220f414418e8e38803a48dfa536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train. loss: 0.07848076227861744, accuracy: 0.8759333333333333\n",
      "Validation. loss: 0.03367219276868614, accuracy: 0.9728\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e14a9dbcd6043e7baa985c8497499e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train. loss: 0.06939990083371271, accuracy: 0.8810333333333333\n",
      "Validation. loss: 0.030216456349393364, accuracy: 0.9719\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa37e91245e4cc393b6eba4d226b366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train. loss: 0.06557267894154228, accuracy: 0.8865166666666666\n",
      "Validation. loss: 0.02797724444205594, accuracy: 0.9761\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce2c5da397944b6a33b3f144faf7f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train. loss: 0.05910745857239786, accuracy: 0.8892666666666666\n",
      "Validation. loss: 0.02738901913450782, accuracy: 0.9784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b14412f06c42b3860a866948d867fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train. loss: 0.056286177248445785, accuracy: 0.8954333333333333\n",
      "Validation. loss: 0.024355998339878907, accuracy: 0.9763\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e640999535d4a5493f237f15a51d619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train. loss: 0.05060757528335205, accuracy: 0.8981\n",
      "Validation. loss: 0.022670915136766282, accuracy: 0.9748\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "config = {\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 10,\n",
    "    'early_stopping': 5,\n",
    "    'lr_reduce_rate': 0.5,\n",
    "    'patience': 3\n",
    "}\n",
    "\n",
    "trainer = MNISTTrainer(model, CrossEntropyLoss(), config, device='cuda')\n",
    "trainer.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
